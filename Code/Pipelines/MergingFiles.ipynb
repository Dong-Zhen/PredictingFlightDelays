{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = r'/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_file_list = ['/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/370DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/371DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/372DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/373DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/374DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/375DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/376DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/377DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/378DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/379DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/380DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/381DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/382DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/383DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/384DL2019.pickle',\n",
    " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/385DL2019.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_airline_data(download_path, merge_list, selection, year, airline):\n",
    "    \n",
    "    airline_file = os.path.join(download_path, f'raw_bts_{selection}_airport_departures{year}.pickle')\n",
    "    \n",
    "    file_path = os.path.join(download_path,f'raw_{selection}{airline}{year}.pickle')\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        \n",
    "        return file_path\n",
    "        \n",
    "        sys.exit('The merge file already exists')\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        to_merge_list = []\n",
    "        \n",
    "        try: \n",
    "\n",
    "            with open(airline_file,'rb') as read_file:\n",
    "                airline_df = pickle.load(read_file)\n",
    "            read_file.close()\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            sys.exit('The file does not exist. Create the file using BTS Scraper.')\n",
    "            \n",
    "        for file in merge_file_list:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                with open(file,'rb') as read_file:\n",
    "                    to_merge_df = pickle.load(read_file)\n",
    "                read_file.close()\n",
    "            \n",
    "            except:\n",
    "                \n",
    "                sys.exit('The file does not exist. Extract relevant year and airline info from airline.csv')\n",
    "                \n",
    "            if to_merge_df.shape[0] == 0:\n",
    "\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "\n",
    "                to_merge_df = to_merge_df[to_merge_df['Origin'].isin(airline_df['Airport'].unique())]\n",
    "\n",
    "                to_merge_list.append(to_merge_df)\n",
    "\n",
    "        raw_merged_df = pd.concat(to_merge_list, axis = 0)\n",
    "\n",
    "        with open(file_path, 'wb') as to_write:\n",
    "\n",
    "            pickle.dump(raw_merged_df, to_write)\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_sheet(download_path, merge_list, selection, year, airline):\n",
    "\n",
    "    with open(os.path.join(download_path, f'raw_bts_{selection}_airport_departures{year}.pickle'),'rb') as read_file:\n",
    "        airline_df1 = pickle.load(read_file)\n",
    "    read_file.close()\n",
    "      \n",
    "    with open(merge_airline_data(download_path, merge_list, selection, year, airline),'rb') as read_file:\n",
    "        airline_df2 = pickle.load(read_file)\n",
    "    read_file.close()\n",
    "    \n",
    "    airline_df2['FlightDate'] = pd.to_datetime(airline_df2['FlightDate'], format = \"%Y-%m-%d\")\n",
    "    airline_df2['FlightDate'] = [date.strftime(\"%m/%d/%Y\") for date in airline_df2['FlightDate']]\n",
    "    \n",
    "    airline_df2[['FlightDate','Tail_Number','Flight_Number_Reporting_Airline','Origin']] = airline_df2[['FlightDate','Tail_Number','Flight_Number_Reporting_Airline','Origin']].astype(str)\n",
    "    airline_df2['Unique_Id'] = airline_df2['FlightDate'] + '-' + airline_df2['Tail_Number'] + '-' + airline_df2['Flight_Number_Reporting_Airline'] + '-' + airline_df2['Origin']\n",
    "    \n",
    "    airline_df1[['Date (MM/DD/YYYY)','Tail Number','Flight Number','Airport']] = airline_df1[['Date (MM/DD/YYYY)','Tail Number','Flight Number','Airport']].astype(str)\n",
    "    airline_df1['Unique_Id'] = airline_df1['Date (MM/DD/YYYY)'] + '-' + airline_df1['Tail Number'] + '-' + airline_df1['Flight Number'] + '-' + airline_df1['Airport']\n",
    "    \n",
    "    airline_df2 = airline_df2[airline_df2['Unique_Id'].isin(airline_df1['Unique_Id'])]\n",
    "    airline_df1 = airline_df1[airline_df1['Unique_Id'].isin(airline_df2['Unique_Id'])]\n",
    "    \n",
    "    airline_df2 = airline_df2[['Unique_Id','OriginCityName', 'OriginStateName', 'DestCityName', 'DestStateName', \n",
    "                               'CRSArrTime', 'ArrTime', 'Cancelled', 'Diverted', 'AirTime', 'Flights', 'Distance']]\n",
    "    airline_df2['ArrDelay'] = airline_df2['ArrTime'] - airline_df2['CRSArrTime']\n",
    "    \n",
    "    merged_df = airline_df1.merge(airline_df2, how = 'left', on = 'Unique_Id')\n",
    "    \n",
    "    merged_df['Delayed Departure'] = (merged_df['Departure delay (Minutes)'] > 15) \n",
    "    merged_df['Delayed Departure'] = merged_df['Delayed Departure'].astype(int)\n",
    "    \n",
    "    merged_df['OriginCityName'] = merged_df['OriginCityName'].str.extract(r\"(.*)\\,\")\n",
    "    merged_df['DestCityName'] = merged_df['DestCityName'].str.extract(r\"(.*)\\,\")\n",
    "    \n",
    "    merged_df = merged_df[['Unique_Id', 'Carrier Code', 'Date (MM/DD/YYYY)', 'Flight Number', 'Tail Number',\n",
    "                       'Airport', 'OriginCityName', 'OriginStateName',\n",
    "                       'Destination Airport', 'DestCityName', 'DestStateName',\n",
    "                       'Scheduled departure time', 'Actual departure time', 'Departure delay (Minutes)',\n",
    "                       'Delayed Departure', 'Scheduled elapsed time (Minutes)', 'Actual elapsed time (Minutes)', \n",
    "                       'Wheels-off time', 'Taxi-Out time (Minutes)', 'Delay Carrier (Minutes)',\n",
    "                       'Delay Weather (Minutes)', 'Delay National Aviation System (Minutes)',\n",
    "                       'Delay Security (Minutes)', 'Delay Late Aircraft Arrival (Minutes)',\n",
    "                       'Cancelled', 'Diverted', 'Flights', 'Distance', \n",
    "                       'CRSArrTime', 'ArrTime', 'ArrDelay', 'AirTime']]\n",
    "    \n",
    "    merged_df.rename(columns = {'Date (MM/DD/YYYY)': 'Flight Date', 'Airport': 'Origin Airport', 'OriginCityName': 'Origin City', 'OriginStateName': 'Origin State',\n",
    "                            'Destination Airport': 'Dest Airport','DestCityName': 'Dest City', 'DestStateName': 'Dest State',\n",
    "                            'Scheduled departure time': 'Scheduled Departure Time', 'Actual departure time': 'Actual Departure Time',\n",
    "                            'Departure delay (Minutes)': 'Minutes Delayed Departing', 'Scheduled elapsed time (Minutes)': 'Scheduled Elapsed Time',\n",
    "                            'Actual elapsed time (Minutes)': 'Actual Elapsed Time', 'Wheels-off time': 'Wheels-off Time', \n",
    "                            'Taxi-Out time (Minutes)': 'Taxi-out Time', 'Delay Carrier (Minutes)': 'Minutes Delayed By Carrier',\n",
    "                            'Delay Weather (Minutes)': 'Minutes Delayed By Weather', 'Delay National Aviation System (Minutes)': 'Minutes Delayed By NAS',\n",
    "                            'Delay Security (Minutes)': 'Minutes Delayed By Security', 'Delay Late Aircraft Arrival (Minutes)': 'Minutes Delayed By Late Arrival',\n",
    "                            'CRSArrTime': 'Scheduled Arrival Time', 'ArrTime': 'Actual Arrival Time', 'ArrDelay': 'Minutes Delayed Arriving'\n",
    "                           }, inplace = True)\n",
    "    \n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_combined_sheet(download_path, merge_file_list, 25, 2019, 'DL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(download_path,'25airportsDL2019.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
