{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_headers_df = pd.read_csv('/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/airlineheaders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_headers = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', \n",
    " 'FlightDate', 'Reporting_Airline', 'Tail_Number', 'Flight_Number_Reporting_Airline', \n",
    " 'Origin', 'OriginCityName', 'OriginState', 'OriginStateName', \n",
    " 'Dest', 'DestCityName', 'DestState', 'DestStateName',\n",
    " 'CRSDepTime', 'DepTime','DepDelay', 'DepDelayMinutes', 'DepDel15', 'DepTimeBlk', \n",
    " 'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn', \n",
    " 'CRSArrTime', 'ArrTime', 'ArrDelay','ArrDelayMinutes', 'ArrDel15', 'ArrTimeBlk', \n",
    " 'Cancelled', 'CancellationCode', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', \n",
    " 'AirTime', 'Flights', 'Distance', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', \n",
    " 'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A breakdown of some of the less obvious field names. \n",
    "\n",
    "- CRSDEPTIME stands for Computer Reservation System (scheduled) Departure Time. \n",
    "\n",
    "- Depature Time is in hhmm format \n",
    "- DepDelay is in minutes\n",
    "- DepDelayMinutes is absolute value of DepDelay\n",
    "- DepDel15 is the delay greater than 15 minutes\n",
    "- DepatureDelayGroups is Depature delay 15 minute interval group\n",
    "\n",
    "- DepTimeBlk stands for Computer Reservation System(scheduled time block)\n",
    "\n",
    "- CRSArrTime Computer Reservation System(scheduled) Arrival Time\n",
    "\n",
    "- Cancelled 1 is canceled\n",
    "- CancellationCode states why the flight is canceled A = Carrier, B = Weather, C = National Air System, D = Security\n",
    "- Diverted 1 = diverted\n",
    "\n",
    "- CRSElapsedTime stands for Computer Reservation System(scheduled) elapsed time\n",
    "\n",
    "- Airtime stands for Flight time in minutes\n",
    "- Flights stands for Number of flights\n",
    "\n",
    "- Distance stands for distance between airports(miles)\n",
    "\n",
    "- FirstDepTime stands for First gate departure time at origin airport\n",
    "\n",
    "- TotalAddGTime stands for Total ground time away from gate\n",
    "\n",
    "- LongestAddGTime stands for Longest time away from gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_df(download_path, headers, chunk_size=500000):\n",
    "    \n",
    "    reader = pd.read_csv(os.path.join(download_path,'airline.csv'), usecols = headers, chunksize=chunk_size, encoding = 'cp1252', low_memory = False, iterator=True)\n",
    "\n",
    "    for chunk in reader:      \n",
    "        \n",
    "        try: \n",
    "            yield chunk\n",
    "        \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_year_dict(download_path, chunk_size=500000):\n",
    "    \n",
    "    file_path = os.path.join(download_path,'yearindex.pkl')\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        year_index_dict = {}\n",
    "        \n",
    "        gen = chunk_df(download_path,'Years', chunk_size)\n",
    "           \n",
    "        for index, df in enumerate(gen):\n",
    "            \n",
    "            try:   \n",
    "                years = df['Year'].unique()\n",
    "            \n",
    "            except:\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            for year in years:\n",
    "                \n",
    "                if year not in year_index_dict:\n",
    "                    \n",
    "                    year_index_dict[year] = []\n",
    "                \n",
    "                year_index_dict[year].append(index)\n",
    "            \n",
    "        f = open(file_path,\"wb\")\n",
    "        pickle.dump(year_index_dict,f, pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(chunk_year_dict(download_path), \"rb\") as read_file:\n",
    "        \n",
    "        year_dict = pickle.load(read_file)\n",
    "    \n",
    "read_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_to_pickle(download_path, year, airline, headers, chunk_size=500000):\n",
    "    \n",
    "    gen = chunk_df(download_path, headers, chunk_size)\n",
    "    \n",
    "    with open(chunk_year_dict(download_path), \"rb\") as read_file:\n",
    "        \n",
    "        year_dict = pickle.load(read_file)\n",
    "    \n",
    "    read_file.close()\n",
    "    \n",
    "    file_path_list = []\n",
    "    \n",
    "    for chunk_index in year_dict[year]:\n",
    "        \n",
    "        file_path = os.path.join(download_path,f'{chunk_index}{airline}{year}.pickle')\n",
    "        \n",
    "        if os.path.isfile(file_path):\n",
    "            \n",
    "            file_path_list.append(file_path)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            pass\n",
    "            \n",
    "    if not file_path_list: \n",
    "    \n",
    "        for index, df in enumerate(gen):\n",
    "\n",
    "            if index not in year_dict[year]:\n",
    "\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "\n",
    "                mask = (df['Year'] == year) & (df['Reporting_Airline'] == airline)\n",
    "\n",
    "                file_path = os.path.join(download_path,f'{index}{airline}{year}.pickle')\n",
    "\n",
    "                with open(file_path, 'wb') as to_write:\n",
    "\n",
    "                    pickle.dump(df[mask], to_write)\n",
    "                \n",
    "                to_write.close()\n",
    "                \n",
    "                file_path_list.append(file_path)\n",
    "    \n",
    "    return file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/370DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/371DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/372DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/373DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/374DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/375DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/376DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/377DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/378DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/379DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/380DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/381DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/382DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/383DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/384DL2019.pickle',\n",
       " '/home/desbrium/Metis/PredictingFlightDelays/Data/BTS Departure Data/385DL2019.pickle']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_to_pickle(download_path, 2019, 'DL', delta_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
